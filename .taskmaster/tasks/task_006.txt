# Task ID: 6
# Title: Implement File Content Caching for Performance
# Status: deferred
# Dependencies: 5
# Priority: medium
# Description: Develop a caching system for file contents to improve performance and reduce disk I/O, especially for large codebases.
# Details:
Create a FileCache class that efficiently manages file content caching:

```typescript
interface CacheEntry {
  content: string;
  timestamp: number;
  size: number;
}

export class FileCache {
  private cache: Map<string, CacheEntry> = new Map();
  private maxCacheSize: number = 50 * 1024 * 1024; // 50MB default
  private currentCacheSize: number = 0;
  
  constructor(maxCacheSizeMB?: number) {
    if (maxCacheSizeMB) {
      this.maxCacheSize = maxCacheSizeMB * 1024 * 1024;
    }
  }
  
  public async getFileContent(filePath: string): Promise<string> {
    // Check if file is in cache and not modified
    const stats = await fs.promises.stat(filePath);
    const cacheEntry = this.cache.get(filePath);
    
    if (cacheEntry && cacheEntry.timestamp >= stats.mtime.getTime()) {
      return cacheEntry.content;
    }
    
    // Read file content
    const content = await fs.promises.readFile(filePath, 'utf8');
    
    // Update cache
    this.addToCache(filePath, content, stats.mtime.getTime());
    
    return content;
  }
  
  private addToCache(filePath: string, content: string, timestamp: number): void {
    const size = Buffer.byteLength(content, 'utf8');
    
    // Remove old entry if exists
    if (this.cache.has(filePath)) {
      const oldEntry = this.cache.get(filePath)!;
      this.currentCacheSize -= oldEntry.size;
    }
    
    // Check if we need to make room in the cache
    if (this.currentCacheSize + size > this.maxCacheSize) {
      this.evictOldEntries(size);
    }
    
    // Add to cache
    this.cache.set(filePath, { content, timestamp, size });
    this.currentCacheSize += size;
  }
  
  private evictOldEntries(sizeNeeded: number): void {
    // Sort entries by timestamp (oldest first)
    const entries = Array.from(this.cache.entries())
      .sort((a, b) => a[1].timestamp - b[1].timestamp);
    
    // Remove oldest entries until we have enough space
    for (const [path, entry] of entries) {
      if (this.currentCacheSize + sizeNeeded <= this.maxCacheSize) {
        break;
      }
      
      this.cache.delete(path);
      this.currentCacheSize -= entry.size;
    }
  }
  
  public clearCache(): void {
    this.cache.clear();
    this.currentCacheSize = 0;
  }
  
  public getCacheStats(): { entryCount: number, sizeBytes: number } {
    return {
      entryCount: this.cache.size,
      sizeBytes: this.currentCacheSize
    };
  }
}
```

Implement an LRU (Least Recently Used) eviction policy to manage cache size. Use file modification timestamps to detect changes and invalidate cache entries. Make the cache size configurable through extension settings. Implement lazy loading to only read files when needed.

# Test Strategy:
1. Test cache hit/miss scenarios with various file operations
2. Verify cache eviction works correctly when size limit is reached
3. Test cache invalidation when files are modified
4. Benchmark performance improvement compared to direct file reading
5. Test with large files to ensure memory usage is controlled
